fill = as.factor(lambda),
group = lambda)
) +
geom_col(position = 'dodge')
plot(dpois(x=0:10,lambda=1),
ylab='dpois(x)',
xlab ='x',
legend("topright", paste("lambda=",lambda)))
plot(dpois(x=0:10,lambda=1),
ylab='dpois(x)',
xlab ='x',
legend("topright", paste("lambda=1")))
plot(dpois(x=0:10,lambda=1),
ylab='dpois(x)',
xlab ='x',
legend("topright", "lambda=1"))
library(ggplot2)
ggplot(data.frame(x=c(0:10)), aes(x)) +
geom_point(aes(y=dpois(x, 1)), colour="red")
plot(dpois(x=0:10,lambda=1),
ylab='dpois(x)',
xlab ='x',
legend("topright", "lambda=1"))
plot(dpois(x=0:10,lambda=.5),
ylab='dpois(x)',
xlab ='x')
ggplot(data.frame(x=c(0:10)), aes(x)) +
geom_point(aes(y=dpois(x, 1)), colour="red")
ggplot(data.frame(x=c(0:10)), aes(x)) +
geom_point(aes(y=dpois(x, .5)), colour="red")
lambdas <- c(.5, 1)
ggplot(data = data.frame(x = 0:10)) +
lapply(lambdas, function(l) geom_point(aes(x = x, y = dpois(x, lambda = l), col = factor(l)))) +
lapply(lambdas, function(l) stat_function(fun = dnorm, args = list(mean = l, sd = sqrt(l)),
aes(x = x, col = factor(l))))
dpois(0,.5)
dpois(1,.5)
dpois(2,.5)
dpois(3,.5)
dpois(4,.5)
dpois(5,.5)
dpois(6,.5)
dpois(0,1)
dpois(1,1)
dpois(2,1)
dpois(3,1)
dpois(4,1)
dpois(5,1)
dpois(6,1)
library(ggplot2)
lambdas <- c(.5, 1)
ggplot(data = data.frame(x = 0:10)) +
lapply(lambdas, function(l) geom_point(aes(x = x, y = dpois(x, lambda = l), col = factor(l)))) +
lapply(lambdas, function(l) stat_function(fun = dnorm, args = list(mean = l, sd = sqrt(l)),
aes(x = x, col = factor(l))) +
+ labs(x = "y") +
+ labs(y = "dpois(x, lambda = l)"))
library(ggplot2)
lambdas <- c(.5, 1)
ggplot(data = data.frame(x = 0:10)) +
lapply(lambdas, function(l) geom_point(aes(x = x, y = dpois(x, lambda = l), col = factor(l)))) +
lapply(lambdas, function(l) stat_function(fun = dnorm, args = list(mean = l, sd = sqrt(l)),
aes(x = x, col = factor(l))) +
labs(x = "y") +
labs(y = "dpois(x, lambda = l)"))
library(tinytex)
update.packages(ask = FALSE, checkBuilt = TRUE)
library(tinytex)
tinytex::tlmgr_update()
update.packages(ask = FALSE, checkBuilt = TRUE)
library(tinytex)
update.packages(ask = FALSE, checkBuilt = TRUE)
library(tinytex)
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
install.packages("plotly")
library(plotly)
install.packages("readxl")
install.packages("jsonlite")
#install.packages("jsonlite")
library(jsonlite)
endPoint="https://data.lacity.org/resource/2nrs-mtv8.json"
LA_Crime_data = fromJSON(endPoint)
head(LA_Crime_data)
library(readxl)
folder="dataFiles"
fileName="UMassChan_ClerkshipGrades.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
ClerkshipGrades_data=read_xlsx(fileToRead)
View(ClerkshipGrades_data)
library(readxl)
folder="dataFiles"
fileName="UMassChan_ClerkshipGrades.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
ClerkshipGrades_data=read_xlsx(fileToRead)
head(ClerkshipGrades_data)
folder="dataFiles"
fileName="Social_Media_and_Mental_Health.csv"
fileToRead=file.path(folder,fileName)
fileToRead
SMMH_data=read.csv(fileToRead)
View(SMMH_data)
#install.packages("jsonlite")
library(jsonlite)
endPoint="https://data.lacity.org/resource/2nrs-mtv8.json"
LA_Crime_data = fromJSON(endPoint)
View(LA_Crime_data)
library(dplyr)
Crime_dirty <- read.csv("https://github.com/DACSS-690R/First_Deliverable/raw/refs/heads/main/dataFiles/Crime_Data_from_2020_to_Present_subset.csv",check.names=F)
Crime_dirty
Crime_dirty[,]=sapply(Crime_dirty[,],trimws)
Crime_clean=Crime_dirty[,]
Crime_clean=Crime_clean[,2:28]
View(Crime_clean)
str(Crime_clean)
Crime_clean <- rename(Crime_clean,
RecordNumber = "dr_no",
DateReported = "date_rptd",
DateOccurred = "date_occ",
TimeOccurred = "time_occ",
GeographicAreaID = "area",
GeographicAreaName = "area_name",
GeographicSubAreaID = "rpt_dist_no",
Part1_2 = "part_1_2",
CrimeCode = "crm_cd",
CrimeCodeDesc = "crm_cd_desc",
VictimAge = "vict_age",
VictimSex = "vict_sex",
VictimEthnicity = "vict_descent",
CrimeSceneCode = "premis_cd",
CrimeSceneDesc = "premis_desc",
CaseStatus = "status",
CaseStatusDesc = "status_desc",
CrimeCode1 = "crm_cd_1",
CrimeCode2 = "crm_cd_2",
AddressCrime = "location",
LatitudeCrime = "lat",
LongitudeCrime = "lon",
CriminalCharacteristicCodes = "mocodes",
WeaponUsedCode = "weapon_used_cd",
WeaponUsedDesc = "weapon_desc",
CrossStreet = "cross_street",
CrimeCode3 = "crm_cd_3")
Crime_clean$DateReported=strptime(Crime_clean$DateReported, "%Y-%m-%dT%H:%M:%S")
Crime_clean$DateOccurred=strptime(Crime_clean$DateOccurred, "%Y-%m-%dT%H:%M:%S")
str(Crime_clean)
table(Crime_clean$GeographicAreaID) #no cleaning needed
table(Crime_clean$GeographicAreaName) #no cleaning needed
table(Crime_clean$GeographicSubAreaID) #no cleaning needed
table(Crime_clean$Part1_2) #no cleaning needed
table(Crime_clean$CrimeCode) #no cleaning needed
table(Crime_clean$CrimeCodeDesc) #no cleaning needed
table(Crime_clean$VictimeAge) #no cleaning needed
table(Crime_clean$VictimSex) #no cleaning needed
table(Crime_clean$VictimEthnicity) #no cleaning needed
table(Crime_clean$CrimeSceneCode) #no cleaning needed
table(Crime_clean$CrimeSceneDesc) #no cleaning needed
table(Crime_clean$CaseStatus) #no cleaning needed
table(Crime_clean$CaseStatusDesc) #no cleaning needed
table(Crime_clean$CrimeCode1) #no cleaning needed
table(Crime_clean$CrimeCode2) #no cleaning needed
table(Crime_clean$AddressCrime) #no cleaning needed
table(Crime_clean$LatitudeCrime) #no cleaning needed
table(Crime_clean$LongitudeCrime) #no cleaning needed
table(Crime_clean$CriminalCharacteristicCodes) #no cleaning needed
table(Crime_clean$WeaponUsedCode) #no cleaning needed
table(Crime_clean$WeaponUsedDesc) #no cleaning needed
table(Crime_clean$CrossStreet) #no cleaning needed
table(Crime_clean$CrimeCode3) #no cleaning needed
folder <- "DataCleanAndFormatted"
# Check if the folder exists
if (!dir.exists(folder)) {
# Create the folder
dir.create(folder)
write.csv(Crime_clean,file.path(folder,"Crime_clean.csv"))
} else {
write.csv(Crime_clean,file.path(folder,"Crime_clean.csv"))}
Crime_clean$AddressCrime_new <- gsub("\\s+", " ", Crime_clean$AddressCrime)
library(dplyr)
library(tidyr)
Crime_clean %>% unnest_wider(CriminalCharacteristicCodes_new, names_sep="_")
library(stringr)
Crime_clean$CriminalCharacteristicCodes_new =  Crime_clean$CriminalCharacteristicCodes
Crime_clean %>% unnest_wider(CriminalCharacteristicCodes_new, names_sep="_")
Crime_clean
setwd("C:/Users/CarlinML/DACSS-690R/Third_Deliverable")
getwd()
ClerkshipGrades <- readRDS(gzcon(url("https://github.com/DACSS-690R/Second_Deliverable/raw/main/DataCleanAndFormatted/ClerkshipGrades_formatted.RDS")))
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...6'] <- 'Session'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...7'] <- 'Session_Code'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Location'] <- 'Location_Code'
ClerkshipGrades$Location_new = ClerkshipGrades$Location_Description
View(ClerkshipGrades)
str(ClerkshipGrades) # 6427 rows
library(readxl)
folder="Data"
fileName="Gender_Ethnicity_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Gender_Ethnicity=read_xlsx(fileToRead)
str(Gender_Ethnicity) # 1004 rows
ClerkshipGrades2 <- merge(ClerkshipGrades,Gender_Ethnicity,all.x=TRUE, by.x="ID", by.y="ID")
str(ClerkshipGrades2) # 6427 rows
folder="Data"
fileName="Location_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Locations=read_xlsx(fileToRead)
str(Locations) # 22 rows
str(merge(ClerkshipGrades2,Locations, by.x='Location_new', by.y='Location'))
# 1877 matched rows
onlyInGrades=sort(setdiff(ClerkshipGrades2$Location_new,Locations$Location))
onlyInGrades
onlyInLocations=sort(setdiff(Locations$Location, ClerkshipGrades2$Location_new))
onlyInLocations
library(stringdist)
stringdist::stringdist(onlyInGrades[1],onlyInLocations,method = 'jaccard')
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInGrades) ) {
allDistances<-stringdist::stringdist(onlyInGrades[i],onlyInLocations,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInLocations[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInGrades,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
fuzzyMatch_notperfect=fuzzyOutput[order(-fuzzyOutput$divergence),]
row.names(fuzzyMatch_notperfect)=NULL
fuzzyMatch_notperfect
fuzzyMatch_notperfect[c(1,2,11),'input']
changes=c('Baystate Medical Center',"UMMHC Hospitals","Berkshire Medical Center")
fuzzyMatch_notperfect[c(1,2,11),'possible_match']=changes
fuzzyMatch_notperfect
fuzzyMatch_Perfect_part1=fuzzyMatch_notperfect[,-3] # without 3rd column
##fuzzyMatch_Perfect_part2?
forPart2=intersect(Locations$Location, ClerkshipGrades2$Location_new)
fuzzyMatch_Perfect_part2=data.frame(cbind(input=forPart2,possible_match=forPart2))
fuzzyMatch_Perfect_part2
# concat
fuzzyMatch_Perfect=rbind(fuzzyMatch_Perfect_part1,fuzzyMatch_Perfect_part2)
names(fuzzyMatch_Perfect)=c('Location_new','location_main')
ClerkshipGrades_withLoc=merge(ClerkshipGrades2,fuzzyMatch_Perfect, by='Location_new',all.x = T)
str(ClerkshipGrades_withLoc)
View(ClerkshipGrades_withLoc)
setwd("C:/Users/CarlinML/DACSS-690R/Second_Deliverable")
getwd()
library(readxl)
destfile <- path.expand("ClerkshipGrades.xlsx")
url      <- paste0("https://github.com/DACSS-690R/First_Deliverable/raw/refs/heads/main/dataFiles/UMassChan_ClerkshipGrades.xlsx")
download.file(url, destfile = destfile, mode = "wb")
ClerkshipGrades_dirty <- read_xlsx(destfile, skip=1)
ClerkshipGrades_dirty
ClerkshipGrades_dirty[,]=sapply(ClerkshipGrades_dirty[,],trimws)
ClerkshipGrades_clean=ClerkshipGrades_dirty[,]
View(ClerkshipGrades_clean)
str(ClerkshipGrades_clean)
ClerkshipGrades_clean <- rename(ClerkshipGrades_clean,
NBME_Letter = `NBME-Written_Letter`,
NBME_Numeric = `NBME-Written_Numeric`)
library("dplyr")
ClerkshipGrades_clean <- rename(ClerkshipGrades_clean,
NBME_Letter = `NBME-Written_Letter`,
NBME_Numeric = `NBME-Written_Numeric`)
table(ClerkshipGrades_clean$Subject) # no cleaning needed
table(ClerkshipGrades_clean$Catalog) # no cleaning needed
table(ClerkshipGrades_clean$Session) # no cleaning needed
table(ClerkshipGrades_clean$Location) # no cleaning needed
table(ClerkshipGrades_clean$Final_Letter)
ClerkshipGrades_clean <- ClerkshipGrades_clean %>%
mutate(Final_Letter2 = recode(Final_Letter,
"HH" = "High Honors",
"H" = "Honors",
"P" = "Pass",
"S" = "Satisfactory",
"F" = "Fail",
"I" = "Incomplete"))
table(ClerkshipGrades_clean$Final_Letter2)
table(ClerkshipGrades_clean$SPE_Letter)
ClerkshipGrades_clean <- ClerkshipGrades_clean %>%
mutate(SPE_Letter2 = recode(SPE_Letter,
"HONORS" = "Honors"))
table(ClerkshipGrades_clean$SPE_Letter2)
table(ClerkshipGrades_clean$NBME_Letter)
ClerkshipGrades_clean <- ClerkshipGrades_clean %>%
mutate(NBME_Letter2 = recode(NBME_Letter,
"HIGH HONORS" = "High Honors",
"HONORS" = "Honors",
"PASS" = "Pass"))
table(ClerkshipGrades_clean$NBME_Letter2)
table(ClerkshipGrades_clean$OSCE_Letter)
ClerkshipGrades_clean <- ClerkshipGrades_clean %>%
mutate(OSCE_Letter2 = recode(OSCE_Letter,
"HIGH HONORS" = "High Honors",
"HONORS" = "Honors",
"PASS" = "Pass"))
table(ClerkshipGrades_clean$OSCE_Letter2)
ClerkshipGrades_clean[!complete.cases(ClerkshipGrades_clean),]
ClerkshipGrades_clean[1,]
colSums(is.na(apply(ClerkshipGrades_clean[,c(10,12,14,16)],2, as.numeric)))
detectWrongNA= function(col){col[grep("[^\\d+\\.*\\d*]", col, perl=T,invert = F)]}
badSymbolNum=sapply(ClerkshipGrades_clean[, c('Final_Numeric','SPE_Numeric','NBME_Numeric', 'OSCE_Numeric')],detectWrongNA)
badSymbolNum_unlist=unlist(badSymbolNum)
badSymbolNum_vector=unique(badSymbolNum_unlist)
badSymbolNum_vector
ClerkshipGrades_clean[, c('Final_Numeric','SPE_Numeric','NBME_Numeric', 'OSCE_Numeric')]=lapply(ClerkshipGrades_clean[, c('Final_Numeric','SPE_Numeric','NBME_Numeric', 'OSCE_Numeric')],function(col) ifelse((col %in% badSymbolNum_vector), NA, col))
ClerkshipGrades_clean
str(ClerkshipGrades_clean)
folder <- "DataCleanAndFormatted"
# Check if the folder exists
if (!dir.exists(folder)) {
# Create the folder
dir.create(folder)
write.csv(SMMH_clean,file.path(folder,"ClerkshipGrades_clean.csv"))
} else {
write.csv(ClerkshipGrades_clean,file.path(folder,"ClerkshipGrades_clean.csv"))}
linkClerkshipGrades_clean='https://github.com/DACSS-690R/Second_Deliverable/raw/refs/heads/main/DataCleanAndFormatted/ClerkshipGrades_clean.csv'
ClerkshipGrades_clean=read.csv(linkClerkshipGrades_clean)
str(ClerkshipGrades_clean)
ClerkshipGrades_clean[,19:22] <- lapply(ClerkshipGrades_clean[,19:22],toupper)
Likert_cols <- c(19:22)
ClerkshipGrades_clean[,Likert_cols] <- lapply(ClerkshipGrades_clean[,Likert_cols] , factor, ordered = TRUE, levels = c("FAIL", "INCOMPLETE", "SATISFACTORY", "PASS", "HONORS", "HIGH HONORS"))
str(ClerkshipGrades_clean)
folder = "DataCleanAndFormatted"
# Check if the folder exists
if (!dir.exists(folder)) {
# Create the folder
dir.create(folder)
saveRDS(ClerkshipGrades_clean,file.path(folder,"
ClerkshipGrades_formatted.RDS"))
} else {
saveRDS(ClerkshipGrades_clean,file.path(folder,"ClerkshipGrades_formatted.RDS"))
}
setwd("C:/Users/CarlinML/DACSS-690R/Third_Deliverable")
getwd()
ClerkshipGrades <- readRDS(gzcon(url("https://github.com/DACSS-690R/Second_Deliverable/raw/main/DataCleanAndFormatted/ClerkshipGrades_formatted.RDS")))
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...6'] <- 'Session'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...7'] <- 'Session_Code'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Location'] <- 'Location_Code'
ClerkshipGrades$Location_new = ClerkshipGrades$Location_Description
str(ClerkshipGrades) # 6427 rows
library(readxl)
folder="Data"
fileName="Gender_Ethnicity_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Gender_Ethnicity=read_xlsx(fileToRead)
str(Gender_Ethnicity) # 1004 rows
ClerkshipGrades2 <- merge(ClerkshipGrades,Gender_Ethnicity,all.x=TRUE, by.x="ID", by.y="ID")
str(ClerkshipGrades2) # 6427 rows
folder="Data"
fileName="Location_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Locations=read_xlsx(fileToRead)
str(Locations) # 22 rows
str(merge(ClerkshipGrades2,Locations, by.x='Location_new', by.y='Location'))
# 1877 matched rows
onlyInGrades=sort(setdiff(ClerkshipGrades2$Location_new,Locations$Location))
onlyInGrades
onlyInLocations=sort(setdiff(Locations$Location, ClerkshipGrades2$Location_new))
onlyInLocations
library(stringdist)
stringdist::stringdist(onlyInGrades[1],onlyInLocations,method = 'jaccard')
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInGrades) ) {
allDistances<-stringdist::stringdist(onlyInGrades[i],onlyInLocations,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInLocations[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInGrades,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
fuzzyMatch_notperfect=fuzzyOutput[order(-fuzzyOutput$divergence),]
row.names(fuzzyMatch_notperfect)=NULL
fuzzyMatch_notperfect
fuzzyMatch_notperfect[c(1,2,11),'input']
changes=c('Baystate Medical Center',"UMMHC Hospitals","Berkshire Medical Center")
fuzzyMatch_notperfect[c(1,2,11),'possible_match']=changes
fuzzyMatch_notperfect
fuzzyMatch_Perfect_part1=fuzzyMatch_notperfect[,-3] # without 3rd column
##fuzzyMatch_Perfect_part2?
forPart2=intersect(Locations$Location, ClerkshipGrades2$Location_new)
fuzzyMatch_Perfect_part2=data.frame(cbind(input=forPart2,possible_match=forPart2))
fuzzyMatch_Perfect_part2
# concat
fuzzyMatch_Perfect=rbind(fuzzyMatch_Perfect_part1,fuzzyMatch_Perfect_part2)
names(fuzzyMatch_Perfect)=c('Location_new','location_main')
ClerkshipGrades_withLoc=merge(ClerkshipGrades2,fuzzyMatch_Perfect, by='Location_new',all.x = T)
str(ClerkshipGrades_withLoc)
View(ClerkshipGrades_withLoc)
ClerkshipGrades_wide <- ClerkshipGrades_withLoc %>% select(-c(X, Title, Session, Location_Code:Final_Letter, SPE_Letter, NBME_Letter, OSCE_Letter, gender, ethnicity))
ClerkshipGrades_wide
ClerkshipGrades_wide <- ClerkshipGrades_withLoc %>% select(-c(Location_new, X, Title, Session, Location_Code:Final_Letter, SPE_Letter, NBME_Letter, OSCE_Letter, gender, ethnicity))
ClerkshipGrades_wide
ClerkshipGrades_withLoc %>%
gather(v, value, f1.avg:f2.sd) %>%
separate(v, c("var", "col")) %>%
arrange(sbj) %>%
spread(col, value)
ClerkshipGrades_wide <- ClerkshipGrades_withLoc %>% select(-c(Location_new, X, Title, Session, Location_Code:Final_Letter, SPE_Letter, NBME_Letter, OSCE_Letter, gender, ethnicity))
ClerkshipGrades_wide
names(ClerkshipGrades_wide) = gsub(pattern = "_Letter2", replacement = "_Letter", x = names(ClerkshipGrades_wide))
ClerkshipGrades_wide
ClerkshipGrades_wide <- ClerkshipGrades_wide %>% relocate(location_main, .before = Final_Numeric)
ClerkshipGrades_wide
ClerkshipGrades_long <- ClerkshipGrades_wide %>%
gather(v, value, Final_Numeric:OSCE_Letter) %>%
separate(v, c("var", "col")) %>%
arrange(ID) %>%
spread(col, value)
library(tidyr)
lerkshipGrades_long <- ClerkshipGrades_wide %>%
gather(v, value, Final_Numeric:OSCE_Letter) %>%
separate(v, c("var", "col")) %>%
arrange(ID) %>%
spread(col, value)
ClerkshipGrades_long
ClerkshipGrades_wide
ClerkshipGrades_long <- ClerkshipGrades_wide %>%
gather(v, value, Final_Numeric:OSCE_Letter) %>%
separate(v, c("var", "col")) %>%
arrange(ID) %>%
spread(col, value)
ClerkshipGrades_long
View(ClerkshipGrades_long)
View(ClerkshipGrades_wide)
table(ClerkshipGrades_wide$Final_Numeric)
table(ClerkshipGrades_wide$Term)
library(tidyverse)
str(ClerkshipGrades_long)
na.omit(ClerkshipGrades_long)
str(ClerkshipGrades_long)
ClerkshipGrades_long <- na.omit(ClerkshipGrades_long)
str(ClerkshipGrades_long)
setwd("C:/Users/CarlinML/DACSS-690R/Third_Deliverable")
getwd()
ClerkshipGrades <- readRDS(gzcon(url("https://github.com/DACSS-690R/Second_Deliverable/raw/main/DataCleanAndFormatted/ClerkshipGrades_formatted.RDS")))
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...6'] <- 'Session'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Session...7'] <- 'Session_Code'
names(ClerkshipGrades)[names(ClerkshipGrades) == 'Location'] <- 'Location_Code'
ClerkshipGrades$Location_new = ClerkshipGrades$Location_Description
str(ClerkshipGrades) # 6427 rows
library(readxl)
folder="Data"
fileName="Gender_Ethnicity_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Gender_Ethnicity=read_xlsx(fileToRead)
str(Gender_Ethnicity) # 1004 rows
ClerkshipGrades2 <- merge(ClerkshipGrades,Gender_Ethnicity,all.x=TRUE, by.x="ID", by.y="ID")
str(ClerkshipGrades2) # 6427 rows
folder="Data"
fileName="Location_info.xlsx"
fileToRead=file.path(folder,fileName)
fileToRead
Locations=read_xlsx(fileToRead)
str(Locations) # 22 rows
str(merge(ClerkshipGrades2,Locations, by.x='Location_new', by.y='Location'))
# 1877 matched rows
onlyInGrades=sort(setdiff(ClerkshipGrades2$Location_new,Locations$Location))
onlyInGrades
onlyInLocations=sort(setdiff(Locations$Location, ClerkshipGrades2$Location_new))
onlyInLocations
library(stringdist)
stringdist::stringdist(onlyInGrades[1],onlyInLocations,method = 'jaccard')
TheMatch<-character()
mindist<-integer()
sortedmatches<-character()
for (i in 1:length(onlyInGrades) ) {
allDistances<-stringdist::stringdist(onlyInGrades[i],onlyInLocations,method = 'jw')
mindist[i]=min(allDistances)
TheMatch[i]<-onlyInLocations[which.min(allDistances)]
}
fuzzyOutput=data.frame(input=onlyInGrades,possible_match=TheMatch,divergence=mindist,  stringsAsFactors = F)
fuzzyOutput[order(-fuzzyOutput$divergence),]
fuzzyMatch_notperfect=fuzzyOutput[order(-fuzzyOutput$divergence),]
row.names(fuzzyMatch_notperfect)=NULL
fuzzyMatch_notperfect
fuzzyMatch_notperfect[c(1,2,11),'input']
changes=c('Baystate Medical Center',"UMMHC Hospitals","Berkshire Medical Center")
fuzzyMatch_notperfect[c(1,2,11),'possible_match']=changes
fuzzyMatch_notperfect
fuzzyMatch_Perfect_part1=fuzzyMatch_notperfect[,-3] # without 3rd column
##fuzzyMatch_Perfect_part2?
forPart2=intersect(Locations$Location, ClerkshipGrades2$Location_new)
fuzzyMatch_Perfect_part2=data.frame(cbind(input=forPart2,possible_match=forPart2))
fuzzyMatch_Perfect_part2
# concat
fuzzyMatch_Perfect=rbind(fuzzyMatch_Perfect_part1,fuzzyMatch_Perfect_part2)
names(fuzzyMatch_Perfect)=c('Location_new','location_main')
ClerkshipGrades_withLoc=merge(ClerkshipGrades2,fuzzyMatch_Perfect, by='Location_new',all.x = T)
str(ClerkshipGrades_withLoc)
View(ClerkshipGrades_withLoc)
ClerkshipGrades_wide <- ClerkshipGrades_withLoc %>% select(-c(Location_new, X, Title, Session, Location_Code:Final_Letter, SPE_Letter, NBME_Letter, OSCE_Letter, gender, ethnicity))
names(ClerkshipGrades_wide) = gsub(pattern = "_Letter2", replacement = "_Letter", x = names(ClerkshipGrades_wide))
ClerkshipGrades_wide <- ClerkshipGrades_wide %>% relocate(location_main, .before = Final_Numeric)
View(ClerkshipGrades_wide)
table(ClerkshipGrades_wide$Term)
library(tidyr)
ClerkshipGrades_long <- ClerkshipGrades_wide %>%
gather(v, value, Final_Numeric:OSCE_Letter) %>%
separate(v, c("var", "col")) %>%
arrange(ID) %>%
spread(col, value)
str(ClerkshipGrades_long) # 25708 rows
# remove rows containing one or more NAs
ClerkshipGrades_long <- na.omit(ClerkshipGrades_long) # 20181 rows
ClerkshipGrades_long
